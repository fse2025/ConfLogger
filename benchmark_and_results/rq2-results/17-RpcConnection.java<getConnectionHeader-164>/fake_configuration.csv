,name,value,description
0,hbase.rpc.crypto.encryption.aes.enabled,,
1,dfs.datanode.directoryscan.threads,1,"How many threads should the threadpool used to compile reports
  for volumes in parallel have."
2,dfs.namenode.available-space-block-placement-policy.balanced-space-tolerance,5,"Only used when the dfs.block.replicator.classname is set to
      org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy.
      Special value between 0 and 20, inclusive. if the value is set beyond the scope,
      this value will be set as 5 by default, Increases tolerance of
      placing blocks on Datanodes with similar disk space used."
3,dfs.client.block.write.replace-datanode-on-failure.min-replication,0,"The minimum number of replications that are needed to not to fail
      the write pipeline if new datanodes can not be found to replace
      failed datanodes (could be due to network failure) in the write pipeline.
      If the number of the remaining datanodes in the write pipeline is greater
      than or equal to this property value, continue writing to the remaining nodes.
      Otherwise throw exception.

      If this is set to 0, an exception will be thrown, when a replacement
      can not be found.
      See also dfs.client.block.write.replace-datanode-on-failure.policy"
4,ha.health-monitor.connect-retry-interval.ms,1000,How often to retry connecting to the service.
5,yarn.app.mapreduce.am.container.log.limit.kb,0,"The maximum size of the MRAppMaster attempt container logs in KB.
    0 disables the cap."
6,dfs.client.failover.sleep.base.millis,500,"Expert only. The time to wait, in milliseconds, between failover
    attempts increases exponentially as a function of the number of
    attempts made so far, with a random factor of +/- 50%. This option
    specifies the base value used in the failover calculation. The
    first failover will retry immediately. The 2nd failover attempt
    will delay at least dfs.client.failover.sleep.base.millis
    milliseconds. And so on."
7,dfs.datanode.du.reserved,0,"Reserved space in bytes per volume. Always leave this much space free for non dfs use.
      Specific storage type based reservation is also supported. The property can be followed with
      corresponding storage types ([ssd]/[disk]/[archive]/[ram_disk]) for cluster with heterogeneous storage.
      For example, reserved space for RAM_DISK storage can be configured using property
      'dfs.datanode.du.reserved.ram_disk'. If specific storage type reservation is not configured
      then dfs.datanode.du.reserved will be used. Support multiple size unit suffix(case insensitive),
      as described in dfs.blocksize.
      Note: In case of using tune2fs to set reserved-blocks-percentage, or other filesystem tools,
      then you can possibly run into out of disk errors because hadoop will not check those
      external tool configurations."
8,yarn.nodemanager.localizer.cache.cleanup.interval-ms,600000,
9,mapreduce.task.exit.timeout.check-interval-ms,20000,"The interval in milliseconds between which the MR framework
  checks if task attempts stay in finishing state for too long."
