,name,value,description
0,dfs.journalnode.https-address,0.0.0.0:8486,
1,dfs.journalnode.https-bind-host,bindHost:port,
2,mapreduce.reduce.maxattempts,4,"Expert: The maximum number of attempts per reduce task.
  In other words, framework will try to execute a reduce task these many number
  of times before giving up on it."
3,ipc.client.connection.maxidletime,10000,"The maximum time in msec after which a client will bring down the
               connection to the server."
4,dfs.datanode.lock-reporting-threshold-ms,300,"When thread waits to obtain a lock, or a thread holds a lock for
    more than the threshold, a log message will be written. Note that
    dfs.lock.suppress.warning.interval ensures a single log message is
    emitted per interval for waiting threads and a single message for holding
    threads to avoid excessive logging."
5,yarn.nodemanager.container-log-monitor.interval-ms,60000,
6,dfs.datanode.socket.write.timeout,480000,Timeout in ms for clients socket writes to DataNodes.
7,dfs.namenode.missing.checkpoint.periods.before.shutdown,3,"The number of checkpoint period windows (as defined by the property
    dfs.namenode.checkpoint.period) allowed by the Namenode to perform
    saving the namespace before shutdown."
8,dfs.client.datanode-restart.timeout,30,"Expert only. The time to wait, in seconds, from reception of an
    datanode shutdown notification for quick restart, until declaring
    the datanode dead and invoking the normal recovery mechanisms.
    The notification is sent by a datanode when it is being shutdown
    using the shutdownDatanode admin command with the upgrade option.
    Support multiple time unit suffix(case insensitive), as described
    in dfs.heartbeat.interval.If no time unit is specified then seconds
    is assumed."
9,mapreduce.reduce.shuffle.retry-delay.max.ms,60000,"The maximum number of ms the reducer will delay before retrying
  to download map data."
10,dfs.qjournal.start-segment.timeout.ms,20000,Quorum timeout in milliseconds for starting a log segment.
