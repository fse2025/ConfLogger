,name,value,description
0,dfs.image.parallel.load,true,
1,fs.s3a.retry.limit,7,"Number of times to retry any repeatable S3 client request on failure,
    excluding throttling requests."
2,dfs.ha.tail-edits.period,60,"How often, the StandbyNode and ObserverNode should check if there are new
    edit log entries ready to be consumed. This is the minimum period between
    checking; exponential backoff will be applied if no edits are found and
    dfs.ha.tail-edits.period.backoff-max is configured. By default, no
    backoff is applied.
    Supports multiple time unit suffix (case insensitive), as described
    in dfs.heartbeat.interval."
3,yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs,20,
4,dfs.namenode.fs-limits.max-blocks-per-file,10000,"Maximum number of blocks per file, enforced by the Namenode on
        write. This prevents the creation of extremely large files which can
        degrade performance."
5,dfs.edit.log.transfer.bandwidthPerSec,0,"Maximum bandwidth used for transferring edit log to between journal nodes
    for syncing, in bytes per second.
    A default value of 0 indicates that throttling is disabled."
6,dfs.namenode.safemode.extension,30000,"Determines extension of safe mode in milliseconds after the threshold level
    is reached.  Support multiple time unit suffix (case insensitive), as
    described in dfs.heartbeat.interval."
7,dfs.namenode.lease-hard-limit-sec,1200,Determines the namenode automatic lease recovery interval in seconds.
8,yarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms,600000,
9,hadoop.security.crypto.buffer.size,8192,The buffer size used by CryptoInputStream and CryptoOutputStream.
