,name,value,description
0,dfs.client.block.write.replace-datanode-on-failure.enable,true,
1,dfs.client.block.write.replace-datanode-on-failure.policy,DEFAULT,
2,dfs.storage.policy.satisfier.work.multiplier.per.iteration,1,"*Note*: Advanced property. Change with caution.
    This determines the total amount of block transfers to begin in
    one iteration, for satisfy the policy. The actual number is obtained by
    multiplying this multiplier with the total number of live nodes in the
    cluster. The result number is the number of blocks to begin transfers
    immediately. This number can be any positive, non-zero integer."
3,dfs.edit.log.transfer.timeout,30000,"Socket timeout for edit log transfer in milliseconds. This timeout
    should be configured such that normal edit log transfer for journal
    node syncing can complete successfully."
4,fs.s3a.socket.send.buffer,8192,Socket send buffer hint to amazon connector. Represented in bytes.
5,dfs.datanode.restart.replica.expiration,50,"During shutdown for restart, the amount of time in seconds budgeted for
    datanode restart."
6,dfs.client.retry.times.get-last-block-length,3,Number of retries for calls to fetchLocatedBlocksAndGetLastBlockLength().
7,dfs.client.failover.connection.retries,0,"Expert only. Indicates the number of retries a failover IPC client
    will make to establish a server connection."
8,dfs.datanode.scan.period.hours,504,"If this is positive, the DataNode will not scan any
        individual block more than once in the specified scan period.
        If this is negative, the block scanner is disabled.
        If this is set to zero, then the default value of 504 hours
        or 3 weeks is used. Prior versions of HDFS incorrectly documented
        that setting this key to zero will disable the block scanner."
9,dfs.datanode.cached-dfsused.check.interval.ms,600000,"The interval check time of loading DU_CACHE_FILE in each volume.
    When the cluster doing the rolling upgrade operations, it will
    usually lead dfsUsed cache file of each volume expired and redo the
    du operations in datanode and that makes datanode start slowly. Adjust
    this property can make cache file be available for the time as you want."
10,yarn.scheduler.configuration.leveldb-store.compaction-interval-secs,86400,
