====================TaintedSinkInfo:=======================
-------------TaintedSinkInfo----------
fileName:	DatanodeManager.java	methodSinagture:	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.initSlowPeerTracker(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/util/Timer;Z)V	methodLines:	374:378
blockLines:	375:-1
paras:	dfs.namenode.checkpoint.txns
TaintedStat:	NORMAL initSlowPeerTracker:conditional branch(eq, to iindex=10) 4,6 Node: < Application, Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager, initSlowPeerTracker(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/util/Timer;Z)V > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere[130]62 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getLong(Ljava/lang/String;J)J > 58,59,60 @303 exception:61
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere[130]62 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getLong(Ljava/lang/String;J)J > 58,59,60 @303 exception:61
NORMAL run:76 = compare 75,62 opcode=cmp Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere
NORMAL run:conditional branch(ge, to iindex=196) 76,28 Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere
NORMAL run:conditional branch(eq, to iindex=231) 81,82 Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere
NORMAL run:87 = invokestatic < Application, Lorg/apache/hadoop/util/Time, monotonicNow()J > @532 exception:86 Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere
METHOD_ENTRY:Node: < Extension, Lorg/apache/hadoop/util/Time, monotonicNow()J > Context: Everywhere
NORMAL monotonicNow:return 5 Node: < Extension, Lorg/apache/hadoop/util/Time, monotonicNow()J > Context: Everywhere
NORMAL_RET_CALLEE:Node: < Extension, Lorg/apache/hadoop/util/Time, monotonicNow()J > Context: Everywhere
NORMAL_RET_CALLER:Node: < Extension, Lorg/apache/hadoop/util/Shell, run()V > Context: Everywhere[5]7 = invokestatic < Extension, Lorg/apache/hadoop/util/Time, monotonicNow()J > @9 exception:6
NORMAL run:8 = compare 5,7 opcode=cmp Node: < Extension, Lorg/apache/hadoop/util/Shell, run()V > Context: Everywhere
NORMAL run:conditional branch(le, to iindex=10) 8,9 Node: < Extension, Lorg/apache/hadoop/util/Shell, run()V > Context: Everywhere
NORMAL run:invokespecial < Extension, Lorg/apache/hadoop/util/Shell, runCommand()V > 1 @37 exception:15 Node: < Extension, Lorg/apache/hadoop/util/Shell, run()V > Context: Everywhere
METHOD_ENTRY:Node: < Extension, Lorg/apache/hadoop/util/Shell, runCommand()V > Context: Everywhere
NORMAL runCommand:invokevirtual < Extension, Ljava/lang/Thread, start()V > 71 @271 exception:73 Node: < Extension, Lorg/apache/hadoop/util/Shell, runCommand()V > Context: Everywhere
METHOD_ENTRY:Node: synthetic < Primordial, Ljava/lang/Thread, start()V > Context: Everywhere
NORMAL start:invokeinterface < Primordial, Ljava/lang/Runnable, run()V > 4 @5 exception:5 Node: synthetic < Primordial, Ljava/lang/Thread, start()V > Context: Everywhere
METHOD_ENTRY:Node: < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase$ReconfigurationThread, run()V > Context: Everywhere
NORMAL run:conditional branch(eq, to iindex=159) 25,26 Node: < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase$ReconfigurationThread, run()V > Context: Everywhere
NORMAL run:conditional branch(ne, to iindex=83) 42,26 Node: < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase$ReconfigurationThread, run()V > Context: Everywhere
NORMAL run:87 = getfield < Extension, Lorg/apache/hadoop/conf/ReconfigurationUtil$PropertyChange, newVal, <Extension,Ljava/lang/String> > 29 Node: < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase$ReconfigurationThread, run()V > Context: Everywhere
PARAM_CALLER:Node: < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase$ReconfigurationThread, run()V > Context: Everywhere[122]89 = invokevirtual < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase, reconfigurePropertyImpl(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > 85,86,87 @277 exception:88 v87
PARAM_CALLEE:Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/NameNode, reconfigurePropertyImpl(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere v3
PARAM_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/NameNode, reconfigurePropertyImpl(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere[132]79 = invokevirtual < Application, Lorg/apache/hadoop/hdfs/server/namenode/NameNode, reconfigureSlowNodesParameters(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > 1,9,2,3 @221 exception:78 v3
PARAM_CALLEE:Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/NameNode, reconfigureSlowNodesParameters(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere v4
NORMAL reconfigureSlowNodesParameters:conditional branch(ne, to iindex=126) 4,47 Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/NameNode, reconfigureSlowNodesParameters(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere
PHI Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/NameNode, reconfigureSlowNodesParameters(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere:56 = phi  17,55
PARAM_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/NameNode, reconfigureSlowNodesParameters(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere[137]invokevirtual < Application, Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager, initSlowPeerTracker(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/util/Timer;Z)V > 2,60,45,56 @342 exception:61 v56
PARAM_CALLEE:Node: < Application, Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager, initSlowPeerTracker(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/util/Timer;Z)V > Context: Everywhere v4
NORMAL initSlowPeerTracker:conditional branch(eq, to iindex=10) 4,6 Node: < Application, Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager, initSlowPeerTracker(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/util/Timer;Z)V > Context: Everywhere



====================ExtendedBlocks:=======================


====================MethodSrc:=======================
      boolean dataNodePeerStatsEnabled) {
    this.slowPeerTracker = dataNodePeerStatsEnabled ?
        new SlowPeerTracker(conf, timer) :
        new SlowPeerDisabledTracker(conf, timer);
  }



====================ctx:=======================
CtxCodeBlock{node=Node: < Application, Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager, <init>(Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockManager;Lorg/apache/hadoop/hdfs/server/namenode/Namesystem;Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere, blocks=[BB[SSA:86..91]39 - org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockManager;Lorg/apache/hadoop/hdfs/server/namenode/Namesystem;Lorg/apache/hadoop/conf/Configuration;)V, BB[SSA:81..85]38 - org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockManager;Lorg/apache/hadoop/hdfs/server/namenode/Namesystem;Lorg/apache/hadoop/conf/Configuration;)V, BB[SSA:92..96]40 - org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockManager;Lorg/apache/hadoop/hdfs/server/namenode/Namesystem;Lorg/apache/hadoop/conf/Configuration;)V, BB[SSA:-1..-2]169 - org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockManager;Lorg/apache/hadoop/hdfs/server/namenode/Namesystem;Lorg/apache/hadoop/conf/Configuration;)V], numberOfBasicBlocks=4, firstLineNumber=251, lastLineNumber=256, firstMethodNumber=229, lastMethodNumber=363, isFirstLineValid=true, methodSrcCode=
  DatanodeManager(final BlockManager blockManager, final Namesystem namesystem,
      final Configuration conf) throws IOException {
    this.namesystem = namesystem;
    this.blockManager = blockManager;

    this.useDfsNetworkTopology = conf.getBoolean(
        DFSConfigKeys.DFS_USE_DFS_NETWORK_TOPOLOGY_KEY,
        DFSConfigKeys.DFS_USE_DFS_NETWORK_TOPOLOGY_DEFAULT);
    if (useDfsNetworkTopology) {
      networktopology = DFSNetworkTopology.getInstance(conf);
    } else {
      networktopology = NetworkTopology.getInstance(conf);
    }
    this.heartbeatManager = new HeartbeatManager(namesystem,
        blockManager, conf);
    this.datanodeAdminManager = new DatanodeAdminManager(namesystem,
        blockManager, heartbeatManager);
    this.fsClusterStats = newFSClusterStats();
    this.dataNodeDiskStatsEnabled = Util.isDiskStatsEnabled(conf.getInt(
        DFSConfigKeys.DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_KEY,
        DFSConfigKeys.
            DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_DEFAULT));
    final Timer timer = new Timer();
    final boolean dataNodePeerStatsEnabledVal =
        conf.getBoolean(DFSConfigKeys.DFS_DATANODE_PEER_STATS_ENABLED_KEY,
            DFSConfigKeys.DFS_DATANODE_PEER_STATS_ENABLED_DEFAULT);
    initSlowPeerTracker(conf, timer, dataNodePeerStatsEnabledVal);
    this.maxSlowPeerReportNodes = conf.getInt(
        DFSConfigKeys.DFS_NAMENODE_MAX_SLOWPEER_COLLECT_NODES_KEY,
        DFSConfigKeys.DFS_NAMENODE_MAX_SLOWPEER_COLLECT_NODES_DEFAULT);
    this.slowPeerCollectionInterval = conf.getTimeDuration(
        DFSConfigKeys.DFS_NAMENODE_SLOWPEER_COLLECT_INTERVAL_KEY,
        DFSConfigKeys.DFS_NAMENODE_SLOWPEER_COLLECT_INTERVAL_DEFAULT,
        TimeUnit.MILLISECONDS);
    if (slowPeerTracker.isSlowPeerTrackerEnabled()) {
      startSlowPeerCollector();
    }
    this.slowDiskTracker = dataNodeDiskStatsEnabled ?
        new SlowDiskTracker(conf, timer) : null;
    this.defaultXferPort = NetUtils.createSocketAddr(
          conf.getTrimmed(DFSConfigKeys.DFS_DATANODE_ADDRESS_KEY,
              DFSConfigKeys.DFS_DATANODE_ADDRESS_DEFAULT)).getPort();
    this.defaultInfoPort = NetUtils.createSocketAddr(
          conf.getTrimmed(DFSConfigKeys.DFS_DATANODE_HTTP_ADDRESS_KEY,
              DFSConfigKeys.DFS_DATANODE_HTTP_ADDRESS_DEFAULT)).getPort();
    this.defaultInfoSecurePort = NetUtils.createSocketAddr(
        conf.getTrimmed(DFSConfigKeys.DFS_DATANODE_HTTPS_ADDRESS_KEY,
            DFSConfigKeys.DFS_DATANODE_HTTPS_ADDRESS_DEFAULT)).getPort();
    this.defaultIpcPort = NetUtils.createSocketAddr(
          conf.getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,
              DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();
    this.hostConfigManager = ReflectionUtils.newInstance(
        conf.getClass(DFSConfigKeys.DFS_NAMENODE_HOSTS_PROVIDER_CLASSNAME_KEY,
            HostFileManager.class, HostConfigManager.class), conf);
    try {
      this.hostConfigManager.refresh();
    } catch (IOException e) {
      LOG.error("error reading hosts files: ", e);
    }
    this.dnsToSwitchMapping = ReflectionUtils.newInstance(
        conf.getClass(DFSConfigKeys.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY, 
            ScriptBasedMapping.class, DNSToSwitchMapping.class), conf);
    this.rejectUnresolvedTopologyDN = conf.getBoolean(
        DFSConfigKeys.DFS_REJECT_UNRESOLVED_DN_TOPOLOGY_MAPPING_KEY,
        DFSConfigKeys.DFS_REJECT_UNRESOLVED_DN_TOPOLOGY_MAPPING_DEFAULT);
    
    // If the dns to switch mapping supports cache, resolve network
    // locations of those hosts in the include list and store the mapping
    // in the cache; so future calls to resolve will be fast.
    if (dnsToSwitchMapping instanceof CachedDNSToSwitchMapping) {
      final ArrayList<String> locations = new ArrayList<>();
      for (InetSocketAddress addr : hostConfigManager.getIncludes()) {
        locations.add(addr.getAddress().getHostAddress());
      }
      dnsToSwitchMapping.resolve(locations);
    }
    heartbeatIntervalSeconds = conf.getTimeDuration(
        DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,
        DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_DEFAULT, TimeUnit.SECONDS);
    heartbeatRecheckInterval = conf.getInt(
        DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY, 
        DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT); // 5 minutes
    this.heartbeatExpireInterval = 2 * heartbeatRecheckInterval
        + 10 * 1000 * heartbeatIntervalSeconds;
    final int configuredBlockInvalidateLimit = conf.getInt(
        DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_KEY,
        DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_DEFAULT);
    // Block invalidate limit also has some dependency on heartbeat interval.
    // Check setBlockInvalidateLimit().
    setBlockInvalidateLimit(configuredBlockInvalidateLimit);
    this.checkIpHostnameInRegistration = conf.getBoolean(
        DFSConfigKeys.DFS_NAMENODE_DATANODE_REGISTRATION_IP_HOSTNAME_CHECK_KEY,
        DFSConfigKeys.DFS_NAMENODE_DATANODE_REGISTRATION_IP_HOSTNAME_CHECK_DEFAULT);
    LOG.info(DFSConfigKeys.DFS_NAMENODE_DATANODE_REGISTRATION_IP_HOSTNAME_CHECK_KEY
        + "=" + checkIpHostnameInRegistration);
    this.avoidStaleDataNodesForRead = conf.getBoolean(
        DFSConfigKeys.DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_READ_KEY,
        DFSConfigKeys.DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_READ_DEFAULT);
    this.avoidSlowDataNodesForRead = conf.getBoolean(
        DFSConfigKeys.DFS_NAMENODE_AVOID_SLOW_DATANODE_FOR_READ_KEY,
        DFSConfigKeys.DFS_NAMENODE_AVOID_SLOW_DATANODE_FOR_READ_DEFAULT);
    this.readConsiderLoad = conf.getBoolean(
        DFSConfigKeys.DFS_NAMENODE_READ_CONSIDERLOAD_KEY,
        DFSConfigKeys.DFS_NAMENODE_READ_CONSIDERLOAD_DEFAULT);
    this.readConsiderStorageType = conf.getBoolean(
        DFSConfigKeys.DFS_NAMENODE_READ_CONSIDERSTORAGETYPE_KEY,
        DFSConfigKeys.DFS_NAMENODE_READ_CONSIDERSTORAGETYPE_DEFAULT);
    if (readConsiderLoad && readConsiderStorageType) {
      LOG.warn(
          "{} and {} are incompatible and only one can be enabled. "
              + "Both are currently enabled. {} will be ignored.",
          DFSConfigKeys.DFS_NAMENODE_READ_CONSIDERLOAD_KEY,
          DFSConfigKeys.DFS_NAMENODE_READ_CONSIDERSTORAGETYPE_KEY,
          DFSConfigKeys.DFS_NAMENODE_READ_CONSIDERSTORAGETYPE_KEY);
    }
    this.avoidStaleDataNodesForWrite = conf.getBoolean(
        DFSConfigKeys.DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_KEY,
        DFSConfigKeys.DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_DEFAULT);
    this.staleInterval = getStaleIntervalFromConf(conf, heartbeatExpireInterval);
    this.ratioUseStaleDataNodesForWrite = conf.getFloat(
        DFSConfigKeys.DFS_NAMENODE_USE_STALE_DATANODE_FOR_WRITE_RATIO_KEY,
        DFSConfigKeys.DFS_NAMENODE_USE_STALE_DATANODE_FOR_WRITE_RATIO_DEFAULT);
    Preconditions.checkArgument(
        (ratioUseStaleDataNodesForWrite > 0 && 
            ratioUseStaleDataNodesForWrite <= 1.0f),
        DFSConfigKeys.DFS_NAMENODE_USE_STALE_DATANODE_FOR_WRITE_RATIO_KEY +
        " = '" + ratioUseStaleDataNodesForWrite + "' is invalid. " +
        "It should be a positive non-zero float value, not greater than 1.0f.");
    this.timeBetweenResendingCachingDirectivesMs = conf.getLong(
        DFSConfigKeys.DFS_NAMENODE_PATH_BASED_CACHE_RETRY_INTERVAL_MS,
        DFSConfigKeys.DFS_NAMENODE_PATH_BASED_CACHE_RETRY_INTERVAL_MS_DEFAULT);
    this.blocksPerPostponedMisreplicatedBlocksRescan = conf.getLong(
        DFSConfigKeys.DFS_NAMENODE_BLOCKS_PER_POSTPONEDBLOCKS_RESCAN_KEY,
        DFSConfigKeys.DFS_NAMENODE_BLOCKS_PER_POSTPONEDBLOCKS_RESCAN_KEY_DEFAULT);
  }

}
CtxCodeBlock{node=Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/NameNode, reconfigureSlowNodesParameters(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere, blocks=[BB[SSA:135..137]58 - org.apache.hadoop.hdfs.server.namenode.NameNode.reconfigureSlowNodesParameters(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;, BB[SSA:131..134]57 - org.apache.hadoop.hdfs.server.namenode.NameNode.reconfigureSlowNodesParameters(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;, BB[SSA:138..138]59 - org.apache.hadoop.hdfs.server.namenode.NameNode.reconfigureSlowNodesParameters(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;], numberOfBasicBlocks=3, firstLineNumber=2455, lastLineNumber=2457, firstMethodNumber=2416, lastMethodNumber=2471, isFirstLineValid=true, methodSrcCode=
      final String property, final String newVal) throws ReconfigurationException {
    BlockManager bm = namesystem.getBlockManager();
    namesystem.writeLock();
    String result;
    try {
      switch (property) {
      case DFS_NAMENODE_AVOID_SLOW_DATANODE_FOR_READ_KEY: {
        boolean enable = (newVal == null ?
            DFS_NAMENODE_AVOID_SLOW_DATANODE_FOR_READ_DEFAULT :
            Boolean.parseBoolean(newVal));
        result = Boolean.toString(enable);
        datanodeManager.setAvoidSlowDataNodesForReadEnabled(enable);
        break;
      }
      case DFS_NAMENODE_BLOCKPLACEMENTPOLICY_EXCLUDE_SLOW_NODES_ENABLED_KEY: {
        boolean enable = (newVal == null ?
            DFS_NAMENODE_BLOCKPLACEMENTPOLICY_EXCLUDE_SLOW_NODES_ENABLED_DEFAULT :
            Boolean.parseBoolean(newVal));
        result = Boolean.toString(enable);
        bm.setExcludeSlowNodesEnabled(enable);
        break;
      }
      case DFS_NAMENODE_MAX_SLOWPEER_COLLECT_NODES_KEY: {
        int maxSlowpeerCollectNodes = (newVal == null ?
            DFS_NAMENODE_MAX_SLOWPEER_COLLECT_NODES_DEFAULT :
            Integer.parseInt(newVal));
        result = Integer.toString(maxSlowpeerCollectNodes);
        datanodeManager.setMaxSlowpeerCollectNodes(maxSlowpeerCollectNodes);
        break;
      }
      case DFS_DATANODE_PEER_STATS_ENABLED_KEY: {
        Timer timer = new Timer();
        if (newVal != null && !newVal.equalsIgnoreCase("true") && !newVal.equalsIgnoreCase(
            "false")) {
          throw new IllegalArgumentException(newVal + " is not boolean value");
        }
        final boolean peerStatsEnabled = newVal == null ?
            DFS_DATANODE_PEER_STATS_ENABLED_DEFAULT :
            Boolean.parseBoolean(newVal);
        result = Boolean.toString(peerStatsEnabled);
        datanodeManager.initSlowPeerTracker(getConf(), timer, peerStatsEnabled);
        break;
      }
      default: {
        throw new IllegalArgumentException(
            "Unexpected property " + property + " in reconfigureSlowNodesParameters");
      }
      }
      LOG.info("RECONFIGURE* changed {} to {}", property, newVal);
      return result;
    } catch (IllegalArgumentException e) {
      throw new ReconfigurationException(property, newVal, getConf().get(
          property), e);
    } finally {
      namesystem.writeUnlock();
    }
  }
}
