====================TaintedSinkInfo:=======================
-------------TaintedSinkInfo----------
fileName:	SplitMetaInfoReader.java	methodSinagture:	org.apache.hadoop.mapreduce.split.SplitMetaInfoReader.readSplitMetaInfo(Lorg/apache/hadoop/mapreduce/JobID;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo;	methodLines:	46:81
blockLines:	52:-1
paras:	mapreduce.job.split.metainfo.maxsize
TaintedStat:	NORMAL readSplitMetaInfo:conditional branch(le, to iindex=43) 19,20 Node: < Application, Lorg/apache/hadoop/mapreduce/split/SplitMetaInfoReader, readSplitMetaInfo(Lorg/apache/hadoop/mapreduce/JobID;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo; > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/split/SplitMetaInfoReader, readSplitMetaInfo(Lorg/apache/hadoop/mapreduce/JobID;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo; > Context: Everywhere[3]9 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getLong(Ljava/lang/String;J)J > 3,6,7 @6 exception:8
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/split/SplitMetaInfoReader, readSplitMetaInfo(Lorg/apache/hadoop/mapreduce/JobID;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo; > Context: Everywhere[3]9 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getLong(Ljava/lang/String;J)J > 3,6,7 @6 exception:8
NORMAL readSplitMetaInfo:19 = compare 9,18 opcode=cmp Node: < Application, Lorg/apache/hadoop/mapreduce/split/SplitMetaInfoReader, readSplitMetaInfo(Lorg/apache/hadoop/mapreduce/JobID;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo; > Context: Everywhere
NORMAL readSplitMetaInfo:conditional branch(le, to iindex=43) 19,20 Node: < Application, Lorg/apache/hadoop/mapreduce/split/SplitMetaInfoReader, readSplitMetaInfo(Lorg/apache/hadoop/mapreduce/JobID;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo; > Context: Everywhere



====================ExtendedBlocks:=======================


====================MethodSrc:=======================
  throws IOException {
    long maxMetaInfoSize = conf.getLong(MRJobConfig.SPLIT_METAINFO_MAXSIZE,
        MRJobConfig.DEFAULT_SPLIT_METAINFO_MAXSIZE);
    Path metaSplitFile = JobSubmissionFiles.getJobSplitMetaFile(jobSubmitDir);
    String jobSplitFile = JobSubmissionFiles.getJobSplitFile(jobSubmitDir).toString();
    FileStatus fStatus = fs.getFileStatus(metaSplitFile);
    if (maxMetaInfoSize > 0 && fStatus.getLen() > maxMetaInfoSize) {
      throw new IOException("Split metadata size exceeded " +
          maxMetaInfoSize +". Aborting job " + jobId);
    }
    FSDataInputStream in = fs.open(metaSplitFile);
    byte[] header = new byte[JobSplit.META_SPLIT_FILE_HEADER.length];
    in.readFully(header);
    if (!Arrays.equals(JobSplit.META_SPLIT_FILE_HEADER, header)) {
      throw new IOException("Invalid header on split file");
    }
    int vers = WritableUtils.readVInt(in);
    if (vers != JobSplit.META_SPLIT_VERSION) {
      in.close();
      throw new IOException("Unsupported split version " + vers);
    }
    int numSplits = WritableUtils.readVInt(in); //TODO: check for insane values
    JobSplit.TaskSplitMetaInfo[] allSplitMetaInfo = 
      new JobSplit.TaskSplitMetaInfo[numSplits];
    for (int i = 0; i < numSplits; i++) {
      JobSplit.SplitMetaInfo splitMetaInfo = new JobSplit.SplitMetaInfo();
      splitMetaInfo.readFields(in);
      JobSplit.TaskSplitIndex splitIndex = new JobSplit.TaskSplitIndex(
          jobSplitFile, 
          splitMetaInfo.getStartOffset());
      allSplitMetaInfo[i] = new JobSplit.TaskSplitMetaInfo(splitIndex, 
          splitMetaInfo.getLocations(), 
          splitMetaInfo.getInputDataLength());
    }
    in.close();
    return allSplitMetaInfo;
  }


====================ctx:=======================
