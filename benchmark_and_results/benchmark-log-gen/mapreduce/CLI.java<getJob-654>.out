====================TaintedSinkInfo:=======================
-------------TaintedSinkInfo----------
fileName:	CLI.java	methodSinagture:	org.apache.hadoop.mapreduce.tools.CLI.getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job;	methodLines:	654:672
blockLines:	662:-1
paras:	yarn.app.mapreduce.client.job.max-retries
TaintedStat:	NORMAL getJob:conditional branch(ge, to iindex=61) 54,9 Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere[4]9 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getInt(Ljava/lang/String;I)I > 5,6,7 @7 exception:8
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere[4]9 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getInt(Ljava/lang/String;I)I > 5,6,7 @7 exception:8
NORMAL getJob:conditional branch(ge, to iindex=61) 54,9 Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere

-------------TaintedSinkInfo----------
fileName:	CLI.java	methodSinagture:	org.apache.hadoop.mapreduce.tools.CLI.getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job;	methodLines:	654:672
blockLines:	663:-1
paras:	yarn.app.mapreduce.client.job.retry-interval
TaintedStat:	NORMAL getJob:conditional branch(eq, to iindex=27) 53,20 Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere[10]15 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getLong(Ljava/lang/String;J)J > 11,12,13 @20 exception:14
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere[10]15 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getLong(Ljava/lang/String;J)J > 11,12,13 @20 exception:14
NORMAL getJob:37 = binaryop(div) 15 , 36 Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere
NORMAL getJob:39 = invokestatic < Application, Ljava/lang/String, valueOf(J)Ljava/lang/String; > 37 @86 exception:38 Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere
METHOD_ENTRY:Node: < Primordial, Ljava/lang/String, valueOf(J)Ljava/lang/String; > Context: Everywhere
NORMAL valueOf:return 4 Node: < Primordial, Ljava/lang/String, valueOf(J)Ljava/lang/String; > Context: Everywhere
NORMAL_RET_CALLEE:Node: < Primordial, Ljava/lang/String, valueOf(J)Ljava/lang/String; > Context: Everywhere
NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere[43]39 = invokestatic < Application, Ljava/lang/String, valueOf(J)Ljava/lang/String; > 37 @86 exception:38
NORMAL getJob:41 = invokevirtual < Application, Ljava/lang/StringBuilder, append(Ljava/lang/String;)Ljava/lang/StringBuilder; > 35,39 @89 exception:40 Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere
METHOD_ENTRY:Node: < Primordial, Ljava/lang/StringBuilder, append(Ljava/lang/String;)Ljava/lang/StringBuilder; > Context: Everywhere
NORMAL append:return 1 Node: < Primordial, Ljava/lang/StringBuilder, append(Ljava/lang/String;)Ljava/lang/StringBuilder; > Context: Everywhere
NORMAL_RET_CALLEE:Node: < Primordial, Ljava/lang/StringBuilder, append(Ljava/lang/String;)Ljava/lang/StringBuilder; > Context: Everywhere
NORMAL_RET_CALLER:Node: < Extension, Lorg/apache/hadoop/conf/Configuration, getClass(Ljava/lang/String;Ljava/lang/Class;Ljava/lang/Class;)Ljava/lang/Class; > Context: Everywhere[24]25 = invokevirtual < Extension, Ljava/lang/StringBuilder, append(Ljava/lang/String;)Ljava/lang/StringBuilder; > 21,23 @48 exception:24
NORMAL getClass:27 = invokevirtual < Extension, Ljava/lang/StringBuilder, toString()Ljava/lang/String; > 25 @51 exception:26 Node: < Extension, Lorg/apache/hadoop/conf/Configuration, getClass(Ljava/lang/String;Ljava/lang/Class;Ljava/lang/Class;)Ljava/lang/Class; > Context: Everywhere
METHOD_ENTRY:Node: < Primordial, Ljava/lang/StringBuilder, toString()Ljava/lang/String; > Context: Everywhere
NORMAL toString:return 14 Node: < Primordial, Ljava/lang/StringBuilder, toString()Ljava/lang/String; > Context: Everywhere
NORMAL_RET_CALLEE:Node: < Primordial, Ljava/lang/StringBuilder, toString()Ljava/lang/String; > Context: Everywhere
NORMAL_RET_CALLER:Node: < Extension, Lorg/apache/hadoop/conf/Configuration, getHexDigits(Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere[41]30 = invokevirtual < Extension, Ljava/lang/StringBuilder, toString()Ljava/lang/String; > 28 @70 exception:29
PHI Node: < Extension, Lorg/apache/hadoop/conf/Configuration, getHexDigits(Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere:31 = phi  22,30
NORMAL getHexDigits:return 31 Node: < Extension, Lorg/apache/hadoop/conf/Configuration, getHexDigits(Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere
NORMAL_RET_CALLEE:Node: < Extension, Lorg/apache/hadoop/conf/Configuration, getHexDigits(Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere
NORMAL_RET_CALLER:Node: < Extension, Lorg/apache/hadoop/conf/Configuration, getInt(Ljava/lang/String;I)I > Context: Everywhere[11]9 = invokespecial < Extension, Lorg/apache/hadoop/conf/Configuration, getHexDigits(Ljava/lang/String;)Ljava/lang/String; > 1,6 @14 exception:8
NORMAL getInt:conditional branch(eq, to iindex=20) 9,7 Node: < Extension, Lorg/apache/hadoop/conf/Configuration, getInt(Ljava/lang/String;I)I > Context: Everywhere
NORMAL getInt:return 14 Node: < Extension, Lorg/apache/hadoop/conf/Configuration, getInt(Ljava/lang/String;I)I > Context: Everywhere
NORMAL_RET_CALLEE:Node: < Extension, Lorg/apache/hadoop/conf/Configuration, getInt(Ljava/lang/String;I)I > Context: Everywhere
NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere[4]9 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getInt(Ljava/lang/String;I)I > 5,6,7 @7 exception:8
NORMAL getJob:conditional branch(ge, to iindex=61) 54,9 Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere
NORMAL getJob:conditional branch(eq, to iindex=27) 53,20 Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, getJob(Lorg/apache/hadoop/mapreduce/JobID;)Lorg/apache/hadoop/mapreduce/Job; > Context: Everywhere



====================ExtendedBlocks:=======================


====================MethodSrc:=======================

    int maxRetry = getConf().getInt(MRJobConfig.MR_CLIENT_JOB_MAX_RETRIES,
        MRJobConfig.DEFAULT_MR_CLIENT_JOB_MAX_RETRIES);
    long retryInterval = getConf()
        .getLong(MRJobConfig.MR_CLIENT_JOB_RETRY_INTERVAL,
            MRJobConfig.DEFAULT_MR_CLIENT_JOB_RETRY_INTERVAL);
    Job job = cluster.getJob(jobid);

    for (int i = 0; i < maxRetry; ++i) {
      if (job != null) {
        return job;
      }
      LOG.info("Could not obtain job info after " + String.valueOf(i + 1)
          + " attempt(s). Sleeping for " + String.valueOf(retryInterval / 1000)
          + " seconds and retrying.");
      Thread.sleep(retryInterval);
      job = cluster.getJob(jobid);
    }
    return job;
  }


====================ctx:=======================
CtxCodeBlock{node=Node: < Application, Lorg/apache/hadoop/mapreduce/tools/CLI, run([Ljava/lang/String;)I > Context: Everywhere, blocks=[BB[SSA:644..644]226 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:641..643]225 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:645..648]227 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:687..687]246 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:684..686]245 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:688..691]247 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:738..738]270 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:735..737]269 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:739..742]271 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:835..835]321 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:832..834]320 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:836..839]322 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:887..887]343 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:884..886]342 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:888..891]344 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:941..941]369 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:938..940]368 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:942..945]370 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1011..1011]399 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1008..1010]398 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1012..1015]400 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1031..1031]409 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1027..1030]408 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1032..1034]410 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1047..1047]416 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1043..1046]415 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1048..1051]417 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1104..1104]445 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1100..1103]444 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1105..1108]446 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1159..1162]474 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1157..1158]473 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1163..1164]475 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1223..1223]503 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1220..1222]502 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I, BB[SSA:1224..1227]504 - org.apache.hadoop.mapreduce.tools.CLI.run([Ljava/lang/String;)I], numberOfBasicBlocks=36, firstLineNumber=489, lastLineNumber=515, firstMethodNumber=89, lastMethodNumber=515, isFirstLineValid=true, methodSrcCode=
  public int run(String[] argv) throws Exception {
    int exitCode = -1;
    if (argv.length < 1) {
      displayUsage("");
      return exitCode;
    }    
    // process arguments
    String cmd = argv[0];
    String submitJobFile = null;
    String jobid = null;
    String taskid = null;
    String historyFileOrJobId = null;
    String historyOutFile = null;
    String historyOutFormat = HistoryViewer.HUMAN_FORMAT;
    String counterGroupName = null;
    String counterName = null;
    JobPriority jp = null;
    String taskType = null;
    String taskState = null;
    int fromEvent = 0;
    int nEvents = 0;
    int jpvalue = 0;
    String configOutFile = null;
    boolean getStatus = false;
    boolean getCounter = false;
    boolean killJob = false;
    boolean listEvents = false;
    boolean viewHistory = false;
    boolean viewAllHistory = false;
    boolean listJobs = false;
    boolean listAllJobs = false;
    boolean listActiveTrackers = false;
    boolean listBlacklistedTrackers = false;
    boolean displayTasks = false;
    boolean killTask = false;
    boolean failTask = false;
    boolean setJobPriority = false;
    boolean logs = false;
    boolean downloadConfig = false;

    if ("-submit".equals(cmd)) {
      if (argv.length != 2) {
        displayUsage(cmd);
        return exitCode;
      }
      submitJobFile = argv[1];
    } else if ("-status".equals(cmd)) {
      if (argv.length != 2) {
        displayUsage(cmd);
        return exitCode;
      }
      jobid = argv[1];
      getStatus = true;
    } else if("-counter".equals(cmd)) {
      if (argv.length != 4) {
        displayUsage(cmd);
        return exitCode;
      }
      getCounter = true;
      jobid = argv[1];
      counterGroupName = argv[2];
      counterName = argv[3];
    } else if ("-kill".equals(cmd)) {
      if (argv.length != 2) {
        displayUsage(cmd);
        return exitCode;
      }
      jobid = argv[1];
      killJob = true;
    } else if ("-set-priority".equals(cmd)) {
      if (argv.length != 3) {
        displayUsage(cmd);
        return exitCode;
      }
      jobid = argv[1];
      try {
        jp = JobPriority.valueOf(argv[2]);
      } catch (IllegalArgumentException iae) {
        try {
          jpvalue = Integer.parseInt(argv[2]);
        } catch (NumberFormatException ne) {
          LOG.info("Error number format: ", ne);
          displayUsage(cmd);
          return exitCode;
        }
      }
      setJobPriority = true; 
    } else if ("-events".equals(cmd)) {
      if (argv.length != 4) {
        displayUsage(cmd);
        return exitCode;
      }
      jobid = argv[1];
      fromEvent = Integer.parseInt(argv[2]);
      nEvents = Integer.parseInt(argv[3]);
      listEvents = true;
    } else if ("-history".equals(cmd)) {
      viewHistory = true;
      if (argv.length < 2 || argv.length > 7) {
        displayUsage(cmd);
        return exitCode;
      }

      // Some arguments are optional while others are not, and some require
      // second arguments.  Due to this, the indexing can vary depending on
      // what's specified and what's left out, as summarized in the below table:
      // [all] <jobHistoryFile|jobId> [-outfile <file>] [-format <human|json>]
      //   1                  2            3       4         5         6
      //   1                  2            3       4
      //   1                  2                              3         4
      //   1                  2
      //                      1            2       3         4         5
      //                      1            2       3
      //                      1                              2         3
      //                      1

      // "all" is optional, but comes first if specified
      int index = 1;
      if ("all".equals(argv[index])) {
        index++;
        viewAllHistory = true;
        if (argv.length == 2) {
          displayUsage(cmd);
          return exitCode;
        }
      }
      // Get the job history file or job id argument
      historyFileOrJobId = argv[index++];
      // "-outfile" is optional, but if specified requires a second argument
      if (argv.length > index + 1 && "-outfile".equals(argv[index])) {
        index++;
        historyOutFile = argv[index++];
      }
      // "-format" is optional, but if specified required a second argument
      if (argv.length > index + 1 && "-format".equals(argv[index])) {
        index++;
        historyOutFormat = argv[index++];
      }
      // Check for any extra arguments that don't belong here
      if (argv.length > index) {
        displayUsage(cmd);
        return exitCode;
      }
    } else if ("-list".equals(cmd)) {
      if (argv.length != 1 && !(argv.length == 2 && "all".equals(argv[1]))) {
        displayUsage(cmd);
        return exitCode;
      }
      if (argv.length == 2 && "all".equals(argv[1])) {
        listAllJobs = true;
      } else {
        listJobs = true;
      }
    } else if("-kill-task".equals(cmd)) {
      if (argv.length != 2) {
        displayUsage(cmd);
        return exitCode;
      }
      killTask = true;
      taskid = argv[1];
    } else if("-fail-task".equals(cmd)) {
      if (argv.length != 2) {
        displayUsage(cmd);
        return exitCode;
      }
      failTask = true;
      taskid = argv[1];
    } else if ("-list-active-trackers".equals(cmd)) {
      if (argv.length != 1) {
        displayUsage(cmd);
        return exitCode;
      }
      listActiveTrackers = true;
    } else if ("-list-blacklisted-trackers".equals(cmd)) {
      if (argv.length != 1) {
        displayUsage(cmd);
        return exitCode;
      }
      listBlacklistedTrackers = true;
    } else if ("-list-attempt-ids".equals(cmd)) {
      if (argv.length != 4) {
        displayUsage(cmd);
        return exitCode;
      }
      jobid = argv[1];
      taskType = argv[2];
      taskState = argv[3];
      displayTasks = true;
      if (!taskTypes.contains(
          org.apache.hadoop.util.StringUtils.toUpperCase(taskType))) {
        System.out.println("Error: Invalid task-type: " + taskType);
        displayUsage(cmd);
        return exitCode;
      }
      if (!taskStates.contains(
          org.apache.hadoop.util.StringUtils.toLowerCase(taskState))) {
        System.out.println("Error: Invalid task-state: " + taskState);
        displayUsage(cmd);
        return exitCode;
      }
    } else if ("-logs".equals(cmd)) {
      if (argv.length == 2 || argv.length ==3) {
        logs = true;
        jobid = argv[1];
        if (argv.length == 3) {
          taskid = argv[2];
        }  else {
          taskid = null;
        }
      } else {
        displayUsage(cmd);
        return exitCode;
      }
    } else if ("-config".equals(cmd)) {
      downloadConfig = true;
      if (argv.length != 3) {
        displayUsage(cmd);
        return exitCode;
      }
      jobid = argv[1];
      configOutFile = argv[2];
    } else {
      displayUsage(cmd);
      return exitCode;
    }

    // initialize cluster
    cluster = createCluster();
        
    // Submit the request
    try {
      if (submitJobFile != null) {
        Job job = Job.getInstance(new JobConf(submitJobFile));
        job.submit();
        System.out.println("Created job " + job.getJobID());
        exitCode = 0;
      } else if (getStatus) {
        Job job = getJob(JobID.forName(jobid));
        if (job == null) {
          System.out.println("Could not find job " + jobid);
        } else {
          Counters counters = job.getCounters();
          System.out.println();
          System.out.println(job);
          if (counters != null) {
            System.out.println(counters);
          } else {
            System.out.println("Counters not available. Job is retired.");
          }
          exitCode = 0;
        }
      } else if (getCounter) {
        Job job = getJob(JobID.forName(jobid));
        if (job == null) {
          System.out.println("Could not find job " + jobid);
        } else {
          Counters counters = job.getCounters();
          if (counters == null) {
            System.out.println("Counters not available for retired job " + 
            jobid);
            exitCode = -1;
          } else {
            System.out.println(getCounter(counters,
              counterGroupName, counterName));
            exitCode = 0;
          }
        }
      } else if (killJob) {
        Job job = getJob(JobID.forName(jobid));
        if (job == null) {
          System.out.println("Could not find job " + jobid);
        } else {
          JobStatus jobStatus = job.getStatus();
          if (jobStatus.getState() == JobStatus.State.FAILED) {
            System.out.println("Could not mark the job " + jobid
                + " as killed, as it has already failed.");
            exitCode = -1;
          } else if (jobStatus.getState() == JobStatus.State.KILLED) {
            System.out
                .println("The job " + jobid + " has already been killed.");
            exitCode = -1;
          } else if (jobStatus.getState() == JobStatus.State.SUCCEEDED) {
            System.out.println("Could not kill the job " + jobid
                + ", as it has already succeeded.");
            exitCode = -1;
          } else {
            job.killJob();
            System.out.println("Killed job " + jobid);
            exitCode = 0;
          }
        }
      } else if (setJobPriority) {
        Job job = getJob(JobID.forName(jobid));
        if (job == null) {
          System.out.println("Could not find job " + jobid);
        } else {
          if (jp != null) {
            job.setPriority(jp);
          } else {
            job.setPriorityAsInteger(jpvalue);
          }
          System.out.println("Changed job priority.");
          exitCode = 0;
        } 
      } else if (viewHistory) {
        // If it ends with .jhist, assume it's a jhist file; otherwise, assume
        // it's a Job ID
        if (historyFileOrJobId.endsWith(".jhist")) {
          viewHistory(historyFileOrJobId, viewAllHistory, historyOutFile,
              historyOutFormat);
          exitCode = 0;
        } else {
          Job job = getJob(JobID.forName(historyFileOrJobId));
          if (job == null) {
            System.out.println("Could not find job " + jobid);
          } else {
            String historyUrl = job.getHistoryUrl();
            if (historyUrl == null || historyUrl.isEmpty()) {
              System.out.println("History file for job " + historyFileOrJobId +
                  " is currently unavailable.");
            } else {
              viewHistory(historyUrl, viewAllHistory, historyOutFile,
                  historyOutFormat);
              exitCode = 0;
            }
          }
        }
      } else if (listEvents) {
        Job job = getJob(JobID.forName(jobid));
        if (job == null) {
          System.out.println("Could not find job " + jobid);
        } else {
          listEvents(job, fromEvent, nEvents);
          exitCode = 0;
        }
      } else if (listJobs) {
        listJobs(cluster);
        exitCode = 0;
      } else if (listAllJobs) {
        listAllJobs(cluster);
        exitCode = 0;
      } else if (listActiveTrackers) {
        listActiveTrackers(cluster);
        exitCode = 0;
      } else if (listBlacklistedTrackers) {
        listBlacklistedTrackers(cluster);
        exitCode = 0;
      } else if (displayTasks) {
        Job job = getJob(JobID.forName(jobid));
        if (job == null) {
          System.out.println("Could not find job " + jobid);
        } else {
          displayTasks(getJob(JobID.forName(jobid)), taskType, taskState);
          exitCode = 0;
        }
      } else if(killTask) {
        TaskAttemptID taskID = TaskAttemptID.forName(taskid);
        Job job = getJob(taskID.getJobID());
        if (job == null) {
          System.out.println("Could not find job " + jobid);
        } else if (job.killTask(taskID, false)) {
          System.out.println("Killed task " + taskid);
          exitCode = 0;
        } else {
          System.out.println("Could not kill task " + taskid);
          exitCode = -1;
        }
      } else if(failTask) {
        TaskAttemptID taskID = TaskAttemptID.forName(taskid);
        Job job = getJob(taskID.getJobID());
        if (job == null) {
            System.out.println("Could not find job " + jobid);
        } else if(job.killTask(taskID, true)) {
          System.out.println("Killed task " + taskID + " by failing it");
          exitCode = 0;
        } else {
          System.out.println("Could not fail task " + taskid);
          exitCode = -1;
        }
      } else if (logs) {
        JobID jobID = JobID.forName(jobid);
        if (getJob(jobID) == null) {
          System.out.println("Could not find job " + jobid);
        } else {
          try {
            TaskAttemptID taskAttemptID = TaskAttemptID.forName(taskid);
            LogParams logParams = cluster.getLogParams(jobID, taskAttemptID);
            LogCLIHelpers logDumper = new LogCLIHelpers();
            logDumper.setConf(getConf());
            exitCode = logDumper.dumpAContainersLogs(
                    logParams.getApplicationId(), logParams.getContainerId(),
                    logParams.getNodeId(), logParams.getOwner());
          } catch (IOException e) {
            if (e instanceof RemoteException) {
              throw e;
            }
            System.out.println(e.getMessage());
          }
        }
      } else if (downloadConfig) {
        Job job = getJob(JobID.forName(jobid));
        if (job == null) {
          System.out.println("Could not find job " + jobid);
        } else {
          String jobFile = job.getJobFile();
          if (jobFile == null || jobFile.isEmpty()) {
            System.out.println("Config file for job " + jobFile +
                " could not be found.");
          } else {
            Path configPath = new Path(jobFile);
            FileSystem fs = FileSystem.get(getConf());
            fs.copyToLocalFile(configPath, new Path(configOutFile));
            exitCode = 0;
          }
        }
      }
    } catch (RemoteException re) {
      IOException unwrappedException = re.unwrapRemoteException();
      if (unwrappedException instanceof AccessControlException) {
        System.out.println(unwrappedException.getMessage());
      } else {
        throw re;
      }
    } finally {
      cluster.close();
    }
    return exitCode;
  }
}
