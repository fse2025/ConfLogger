====================TaintedSinkInfo:=======================
-------------TaintedSinkInfo----------
fileName:	JobImpl.java	methodSinagture:	org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.isChainJob(Lorg/apache/hadoop/conf/Configuration;)Z	methodLines:	1320:1344
blockLines:	1335:-1
paras:	null
TaintedStat:	NORMAL isChainJob:conditional branch(eq, to iindex=40) 23,8 Node: < Application, Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl, isChainJob(Lorg/apache/hadoop/conf/Configuration;)Z > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl, isChainJob(Lorg/apache/hadoop/conf/Configuration;)Z > Context: Everywhere[25]23 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, get(Ljava/lang/String;)Ljava/lang/String; > 2,21 @45 exception:22
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl, isChainJob(Lorg/apache/hadoop/conf/Configuration;)Z > Context: Everywhere[25]23 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, get(Ljava/lang/String;)Ljava/lang/String; > 2,21 @45 exception:22
NORMAL isChainJob:conditional branch(eq, to iindex=40) 23,8 Node: < Application, Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl, isChainJob(Lorg/apache/hadoop/conf/Configuration;)Z > Context: Everywhere

-------------TaintedSinkInfo----------
fileName:	JobImpl.java	methodSinagture:	org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.isChainJob(Lorg/apache/hadoop/conf/Configuration;)Z	methodLines:	1320:1344
blockLines:	1324:-1
paras:	null
TaintedStat:	NORMAL isChainJob:conditional branch(eq, to iindex=19) 7,8 Node: < Application, Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl, isChainJob(Lorg/apache/hadoop/conf/Configuration;)Z > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl, isChainJob(Lorg/apache/hadoop/conf/Configuration;)Z > Context: Everywhere[4]7 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, get(Ljava/lang/String;)Ljava/lang/String; > 2,5 @6 exception:6
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl, isChainJob(Lorg/apache/hadoop/conf/Configuration;)Z > Context: Everywhere[4]7 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, get(Ljava/lang/String;)Ljava/lang/String; > 2,5 @6 exception:6
NORMAL isChainJob:conditional branch(eq, to iindex=19) 7,8 Node: < Application, Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl, isChainJob(Lorg/apache/hadoop/conf/Configuration;)Z > Context: Everywhere



====================ExtendedBlocks:=======================


====================MethodSrc:=======================
  private boolean isChainJob(Configuration conf) {
    boolean isChainJob = false;
    try {
      String mapClassName = conf.get(MRJobConfig.MAP_CLASS_ATTR);
      if (mapClassName != null) {
        Class<?> mapClass = Class.forName(mapClassName);
        if (ChainMapper.class.isAssignableFrom(mapClass))
          isChainJob = true;
      }
    } catch (ClassNotFoundException cnfe) {
      // don't care; assume it's not derived from ChainMapper
    } catch (NoClassDefFoundError ignored) {
    }
    try {
      String reduceClassName = conf.get(MRJobConfig.REDUCE_CLASS_ATTR);
      if (reduceClassName != null) {
        Class<?> reduceClass = Class.forName(reduceClassName);
        if (ChainReducer.class.isAssignableFrom(reduceClass))
          isChainJob = true;
      }
    } catch (ClassNotFoundException cnfe) {
      // don't care; assume it's not derived from ChainReducer
    } catch (NoClassDefFoundError ignored) {
    }
    return isChainJob;
  }


====================ctx:=======================
CtxCodeBlock{node=Node: < Application, Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl, makeUberDecision(J)V > Context: Everywhere, blocks=[BB[SSA:134..134]48 - org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.makeUberDecision(J)V, BB[SSA:130..133]47 - org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.makeUberDecision(J)V, BB[SSA:135..136]49 - org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.makeUberDecision(J)V, BB[SSA:-1..-2]124 - org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.makeUberDecision(J)V], numberOfBasicBlocks=4, firstLineNumber=1262, lastLineNumber=1263, firstMethodNumber=1220, lastMethodNumber=1314, isFirstLineValid=true, methodSrcCode=
    // these are no longer "system" settings, necessarily; user may override
    int sysMaxMaps = conf.getInt(MRJobConfig.JOB_UBERTASK_MAXMAPS, 9);

    int sysMaxReduces = conf.getInt(MRJobConfig.JOB_UBERTASK_MAXREDUCES, 1);

    long sysMaxBytes = conf.getLong(MRJobConfig.JOB_UBERTASK_MAXBYTES,
        fs.getDefaultBlockSize(this.remoteJobSubmitDir)); // FIXME: this is wrong; get FS from
                                   // [File?]InputFormat and default block size
                                   // from that

    long sysMemSizeForUberSlot =
        conf.getInt(MRJobConfig.MR_AM_VMEM_MB,
            MRJobConfig.DEFAULT_MR_AM_VMEM_MB);

    long sysCPUSizeForUberSlot =
        conf.getInt(MRJobConfig.MR_AM_CPU_VCORES,
            MRJobConfig.DEFAULT_MR_AM_CPU_VCORES);

    boolean uberEnabled =
        conf.getBoolean(MRJobConfig.JOB_UBERTASK_ENABLE, false);
    boolean smallNumMapTasks = (numMapTasks <= sysMaxMaps);
    boolean smallNumReduceTasks = (numReduceTasks <= sysMaxReduces);
    boolean smallInput = (dataInputLength <= sysMaxBytes);
    // ignoring overhead due to UberAM and statics as negligible here:
    long requiredMapMB = conf.getLong(MRJobConfig.MAP_MEMORY_MB, 0);
    long requiredReduceMB = conf.getLong(MRJobConfig.REDUCE_MEMORY_MB, 0);
    long requiredMB = Math.max(requiredMapMB, requiredReduceMB);
    int requiredMapCores = conf.getInt(
            MRJobConfig.MAP_CPU_VCORES, 
            MRJobConfig.DEFAULT_MAP_CPU_VCORES);
    int requiredReduceCores = conf.getInt(
            MRJobConfig.REDUCE_CPU_VCORES, 
            MRJobConfig.DEFAULT_REDUCE_CPU_VCORES);
    int requiredCores = Math.max(requiredMapCores, requiredReduceCores);    
    if (numReduceTasks == 0) {
      requiredMB = requiredMapMB;
      requiredCores = requiredMapCores;
    }
    boolean smallMemory =
        (requiredMB <= sysMemSizeForUberSlot)
        || (sysMemSizeForUberSlot == JobConf.DISABLED_MEMORY_LIMIT);
    
    boolean smallCpu = requiredCores <= sysCPUSizeForUberSlot;
    boolean notChainJob = !isChainJob(conf);

    // User has overall veto power over uberization, or user can modify
    // limits (overriding system settings and potentially shooting
    // themselves in the head).  Note that ChainMapper/Reducer are
    // fundamentally incompatible with MR-1220; they employ a blocking
    // queue between the maps/reduces and thus require parallel execution,
    // while "uber-AM" (MR AM + LocalContainerLauncher) loops over tasks
    // and thus requires sequential execution.
    isUber = uberEnabled && smallNumMapTasks && smallNumReduceTasks
        && smallInput && smallMemory && smallCpu 
        && notChainJob;

    if (isUber) {
      LOG.info("Uberizing job " + jobId + ": " + numMapTasks + "m+"
          + numReduceTasks + "r tasks (" + dataInputLength
          + " input bytes) will run sequentially on single node.");

      // make sure reduces are scheduled only after all map are completed
      conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART,
                        1.0f);
      // uber-subtask attempts all get launched on same node; if one fails,
      // probably should retry elsewhere, i.e., move entire uber-AM:  ergo,
      // limit attempts to 1 (or at most 2?  probably not...)
      conf.setInt(MRJobConfig.MAP_MAX_ATTEMPTS, 1);
      conf.setInt(MRJobConfig.REDUCE_MAX_ATTEMPTS, 1);

      // disable speculation
      conf.setBoolean(MRJobConfig.MAP_SPECULATIVE, false);
      conf.setBoolean(MRJobConfig.REDUCE_SPECULATIVE, false);
    } else {
      StringBuilder msg = new StringBuilder();
      msg.append("Not uberizing ").append(jobId).append(" because:");
      if (!uberEnabled)
        msg.append(" not enabled;");
      if (!smallNumMapTasks)
        msg.append(" too many maps;");
      if (!smallNumReduceTasks)
        msg.append(" too many reduces;");
      if (!smallInput)
        msg.append(" too much input;");
      if (!smallCpu)
        msg.append(" too much CPU;");
      if (!smallMemory)
        msg.append(" too much RAM;");
      if (!smallCpu)
          msg.append(" too much CPU;");
      if (!notChainJob)
        msg.append(" chainjob;");
      LOG.info(msg.toString());
    }
  }
  
}
