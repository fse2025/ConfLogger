====================TaintedSinkInfo:=======================
-------------TaintedSinkInfo----------
fileName:	JobSubmitter.java	methodSinagture:	org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(Lorg/apache/hadoop/conf/Configuration;)V	methodLines:	438:471
blockLines:	441:-1
paras:	mapreduce.application.framework.path
TaintedStat:	NORMAL addMRFrameworkToDistributedCache:conditional branch(ne, to iindex=86) 8,9 Node: < Application, Lorg/apache/hadoop/mapreduce/JobSubmitter, addMRFrameworkToDistributedCache(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/JobSubmitter, addMRFrameworkToDistributedCache(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere[3]6 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, get(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > 1,3,4 @5 exception:5
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/JobSubmitter, addMRFrameworkToDistributedCache(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere[3]6 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, get(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > 1,3,4 @5 exception:5
NORMAL addMRFrameworkToDistributedCache:8 = invokevirtual < Application, Ljava/lang/String, isEmpty()Z > 6 @10 exception:7 Node: < Application, Lorg/apache/hadoop/mapreduce/JobSubmitter, addMRFrameworkToDistributedCache(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere
METHOD_ENTRY:Node: < Primordial, Ljava/lang/String, isEmpty()Z > Context: Everywhere
NORMAL isEmpty:return 7 Node: < Primordial, Ljava/lang/String, isEmpty()Z > Context: Everywhere
NORMAL_RET_CALLEE:Node: < Primordial, Ljava/lang/String, isEmpty()Z > Context: Everywhere
NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/mapreduce/JobSubmitter, addMRFrameworkToDistributedCache(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere[6]8 = invokevirtual < Application, Ljava/lang/String, isEmpty()Z > 6 @10 exception:7
NORMAL addMRFrameworkToDistributedCache:conditional branch(ne, to iindex=86) 8,9 Node: < Application, Lorg/apache/hadoop/mapreduce/JobSubmitter, addMRFrameworkToDistributedCache(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere



====================ExtendedBlocks:=======================


====================MethodSrc:=======================
      throws IOException {
    String framework =
        conf.get(MRJobConfig.MAPREDUCE_APPLICATION_FRAMEWORK_PATH, "");
    if (!framework.isEmpty()) {
      URI uri;
      try {
        uri = new URI(framework);
      } catch (URISyntaxException e) {
        throw new IllegalArgumentException("Unable to parse '" + framework
            + "' as a URI, check the setting for "
            + MRJobConfig.MAPREDUCE_APPLICATION_FRAMEWORK_PATH, e);
      }

      String linkedName = uri.getFragment();

      // resolve any symlinks in the URI path so using a "current" symlink
      // to point to a specific version shows the specific version
      // in the distributed cache configuration
      FileSystem fs = FileSystem.get(uri, conf);
      Path frameworkPath = fs.makeQualified(
          new Path(uri.getScheme(), uri.getAuthority(), uri.getPath()));
      FileContext fc = FileContext.getFileContext(frameworkPath.toUri(), conf);
      frameworkPath = fc.resolvePath(frameworkPath);
      uri = frameworkPath.toUri();
      try {
        uri = new URI(uri.getScheme(), uri.getAuthority(), uri.getPath(),
            null, linkedName);
      } catch (URISyntaxException e) {
        throw new IllegalArgumentException(e);
      }

      Job.addCacheArchive(uri, conf);
    }
  }
}


====================ctx:=======================
CtxCodeBlock{node=Node: < Application, Lorg/apache/hadoop/mapreduce/JobSubmitter, submitJobInternal(Lorg/apache/hadoop/mapreduce/Job;Lorg/apache/hadoop/mapreduce/Cluster;)Lorg/apache/hadoop/mapreduce/JobStatus; > Context: Everywhere, blocks=[BB[SSA:5..7]3 - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(Lorg/apache/hadoop/mapreduce/Job;Lorg/apache/hadoop/mapreduce/Cluster;)Lorg/apache/hadoop/mapreduce/JobStatus;, BB[SSA:3..4]2 - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(Lorg/apache/hadoop/mapreduce/Job;Lorg/apache/hadoop/mapreduce/Cluster;)Lorg/apache/hadoop/mapreduce/JobStatus;, BB[SSA:8..10]4 - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(Lorg/apache/hadoop/mapreduce/Job;Lorg/apache/hadoop/mapreduce/Cluster;)Lorg/apache/hadoop/mapreduce/JobStatus;, BB[SSA:-1..-2]162 - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(Lorg/apache/hadoop/mapreduce/Job;Lorg/apache/hadoop/mapreduce/Cluster;)Lorg/apache/hadoop/mapreduce/JobStatus;], numberOfBasicBlocks=4, firstLineNumber=145, lastLineNumber=148, firstMethodNumber=142, lastMethodNumber=265, isFirstLineValid=true, methodSrcCode=
    //validate the jobs output specs 
    checkSpecs(job);

    Configuration conf = job.getConfiguration();
    addMRFrameworkToDistributedCache(conf);

    Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);
    //configure the command line options correctly on the submitting dfs
    InetAddress ip = InetAddress.getLocalHost();
    if (ip != null) {
      submitHostAddress = ip.getHostAddress();
      submitHostName = ip.getHostName();
      conf.set(MRJobConfig.JOB_SUBMITHOST,submitHostName);
      conf.set(MRJobConfig.JOB_SUBMITHOSTADDR,submitHostAddress);
    }
    JobID jobId = submitClient.getNewJobID();
    job.setJobID(jobId);
    Path submitJobDir = new Path(jobStagingArea, jobId.toString());
    JobStatus status = null;
    try {
      conf.set(MRJobConfig.USER_NAME,
          UserGroupInformation.getCurrentUser().getShortUserName());
      conf.set("hadoop.http.filter.initializers", 
          "org.apache.hadoop.yarn.server.webproxy.amfilter.AmFilterInitializer");
      conf.set(MRJobConfig.MAPREDUCE_JOB_DIR, submitJobDir.toString());
      LOG.debug("Configuring job " + jobId + " with " + submitJobDir 
          + " as the submit dir");
      // get delegation token for the dir
      TokenCache.obtainTokensForNamenodes(job.getCredentials(),
          new Path[] { submitJobDir }, conf);
      
      populateTokenCache(conf, job.getCredentials());

      // generate a secret to authenticate shuffle transfers
      if (TokenCache.getShuffleSecretKey(job.getCredentials()) == null) {
        KeyGenerator keyGen;
        try {
          keyGen = KeyGenerator.getInstance(SHUFFLE_KEYGEN_ALGORITHM);
          keyGen.init(SHUFFLE_KEY_LENGTH);
        } catch (NoSuchAlgorithmException e) {
          throw new IOException("Error generating shuffle secret key", e);
        }
        SecretKey shuffleKey = keyGen.generateKey();
        TokenCache.setShuffleSecretKey(shuffleKey.getEncoded(),
            job.getCredentials());
      }
      if (CryptoUtils.isEncryptedSpillEnabled(conf)) {
        conf.setInt(MRJobConfig.MR_AM_MAX_ATTEMPTS, 1);
        LOG.warn("Max job attempts set to 1 since encrypted intermediate" +
                "data spill is enabled");
      }

      copyAndConfigureFiles(job, submitJobDir);

      Path submitJobFile = JobSubmissionFiles.getJobConfPath(submitJobDir);
      
      // Create the splits for the job
      LOG.debug("Creating splits at " + jtFs.makeQualified(submitJobDir));
      int maps = writeSplits(job, submitJobDir);
      conf.setInt(MRJobConfig.NUM_MAPS, maps);
      LOG.info("number of splits:" + maps);

      int maxMaps = conf.getInt(MRJobConfig.JOB_MAX_MAP,
          MRJobConfig.DEFAULT_JOB_MAX_MAP);
      if (maxMaps >= 0 && maxMaps < maps) {
        throw new IllegalArgumentException("The number of map tasks " + maps +
            " exceeded limit " + maxMaps);
      }

      // write "queue admins of the queue to which job is being submitted"
      // to job file.
      String queue = conf.get(MRJobConfig.QUEUE_NAME,
          JobConf.DEFAULT_QUEUE_NAME);
      AccessControlList acl = submitClient.getQueueAdmins(queue);
      conf.set(toFullPropertyName(queue,
          QueueACL.ADMINISTER_JOBS.getAclName()), acl.getAclString());

      // removing jobtoken referrals before copying the jobconf to HDFS
      // as the tasks don't need this setting, actually they may break
      // because of it if present as the referral will point to a
      // different job.
      TokenCache.cleanUpTokenReferral(conf);

      if (conf.getBoolean(
          MRJobConfig.JOB_TOKEN_TRACKING_IDS_ENABLED,
          MRJobConfig.DEFAULT_JOB_TOKEN_TRACKING_IDS_ENABLED)) {
        // Add HDFS tracking ids
        ArrayList<String> trackingIds = new ArrayList<String>();
        for (Token<? extends TokenIdentifier> t :
            job.getCredentials().getAllTokens()) {
          trackingIds.add(t.decodeIdentifier().getTrackingId());
        }
        conf.setStrings(MRJobConfig.JOB_TOKEN_TRACKING_IDS,
            trackingIds.toArray(new String[trackingIds.size()]));
      }

      // Set reservation info if it exists
      ReservationId reservationId = job.getReservationId();
      if (reservationId != null) {
        conf.set(MRJobConfig.RESERVATION_ID, reservationId.toString());
      }

      // Write job file to submit dir
      writeConf(conf, submitJobFile);
      
      //
      // Now, actually submit the job (using the submit name)
      //
      printTokens(jobId, job.getCredentials());
      status = submitClient.submitJob(
          jobId, submitJobDir.toString(), job.getCredentials());
      if (status != null) {
        return status;
      } else {
        throw new IOException("Could not launch job");
      }
    } finally {
      if (status == null) {
        LOG.info("Cleaning up the staging area " + submitJobDir);
        if (jtFs != null && submitJobDir != null)
          jtFs.delete(submitJobDir, true);

      }
    }
  }
}
