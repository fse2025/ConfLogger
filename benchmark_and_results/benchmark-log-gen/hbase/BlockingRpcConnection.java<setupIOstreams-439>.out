====================TaintedSinkInfo:=======================
-------------TaintedSinkInfo----------
fileName:	BlockingRpcConnection.java	methodSinagture:	org.apache.hadoop.hbase.ipc.BlockingRpcConnection.setupIOstreams()V	methodLines:	439:528
blockLines:	473:-1
paras:	null
TaintedStat:	NORMAL setupIOstreams:conditional branch(ne, to iindex=111) 52,4 Node: < Application, Lorg/apache/hadoop/hbase/ipc/BlockingRpcConnection, setupIOstreams()V > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/hbase/ipc/BlockingRpcConnection, setupIOstreams()V > Context: Everywhere[101]52 = invokeinterface < Application, Lorg/apache/hadoop/hbase/security/provider/SaslClientAuthenticationProvider, getRealUser(Lorg/apache/hadoop/hbase/security/User;)Lorg/apache/hadoop/security/UserGroupInformation; > 48,50 @230 exception:51
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/hbase/ipc/BlockingRpcConnection, setupIOstreams()V > Context: Everywhere[101]52 = invokeinterface < Application, Lorg/apache/hadoop/hbase/security/provider/SaslClientAuthenticationProvider, getRealUser(Lorg/apache/hadoop/hbase/security/User;)Lorg/apache/hadoop/security/UserGroupInformation; > 48,50 @230 exception:51
NORMAL setupIOstreams:conditional branch(ne, to iindex=111) 52,4 Node: < Application, Lorg/apache/hadoop/hbase/ipc/BlockingRpcConnection, setupIOstreams()V > Context: Everywhere



====================ExtendedBlocks:=======================


====================MethodSrc:=======================
  private void setupIOstreams() throws IOException {
    if (socket != null) {
      // The connection is already available. Perfect.
      return;
    }

    if (this.rpcClient.failedServers.isFailedServer(remoteId.getAddress())) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("Not trying to connect to " + remoteId.getAddress()
          + " this server is in the failed servers list");
      }
      throw new FailedServerException(
        "This server is in the failed servers list: " + remoteId.getAddress());
    }

    try {
      if (LOG.isDebugEnabled()) {
        LOG.debug("Connecting to " + remoteId.getAddress());
      }

      short numRetries = 0;
      int reloginMaxRetries = this.rpcClient.conf.getInt("hbase.security.relogin.maxretries", 5);
      while (true) {
        setupConnection();
        InputStream inStream = NetUtils.getInputStream(socket);
        // This creates a socket with a write timeout. This timeout cannot be changed.
        OutputStream outStream = NetUtils.getOutputStream(socket, this.rpcClient.writeTO);
        // Write out the preamble -- MAGIC, version, and auth to use.
        writeConnectionHeaderPreamble(outStream);
        if (useSasl) {
          final InputStream in2 = inStream;
          final OutputStream out2 = outStream;
          UserGroupInformation ticket = provider.getRealUser(remoteId.ticket);
          boolean continueSasl;
          if (ticket == null) {
            throw new FatalConnectionException("ticket/user is null");
          }
          try {
            continueSasl = ticket.doAs(new PrivilegedExceptionAction<Boolean>() {
              @Override
              public Boolean run() throws IOException {
                return setupSaslConnection(in2, out2);
              }
            });
          } catch (Exception ex) {
            ExceptionUtil.rethrowIfInterrupt(ex);
            handleSaslConnectionFailure(numRetries++, reloginMaxRetries, ex, ticket);
            continue;
          }
          if (continueSasl) {
            // Sasl connect is successful. Let's set up Sasl i/o streams.
            inStream = saslRpcClient.getInputStream();
            outStream = saslRpcClient.getOutputStream();
          } else {
            // fall back to simple auth because server told us so.
            // do not change authMethod and useSasl here, we should start from secure when
            // reconnecting because regionserver may change its sasl config after restart.
          }
        }
        this.in = new DataInputStream(new BufferedInputStream(inStream));
        this.out = new DataOutputStream(new BufferedOutputStream(outStream));
        // Now write out the connection header
        writeConnectionHeader();
        // process the response from server for connection header if necessary
        processResponseForConnectionHeader();

        break;
      }
    } catch (Throwable t) {
      closeSocket();
      IOException e = ExceptionUtil.asInterrupt(t);
      if (e == null) {
        this.rpcClient.failedServers.addToFailedServers(remoteId.getAddress(), t);
        if (t instanceof LinkageError) {
          // probably the hbase hadoop version does not match the running hadoop version
          e = new DoNotRetryIOException(t);
        } else if (t instanceof IOException) {
          e = (IOException) t;
        } else {
          e = new IOException("Could not set up IO Streams to " + remoteId.getAddress(), t);
        }
      }
      throw e;
    }

    // start the receiver thread after the socket connection has been set up
    thread = new Thread(this, threadName);
    thread.setDaemon(true);
    thread.start();
  }



====================ctx:=======================
CtxCodeBlock{node=Node: < Application, Lorg/apache/hadoop/hbase/ipc/BlockingRpcConnection, writeRequest(Lorg/apache/hadoop/hbase/ipc/Call;)V > Context: Everywhere, blocks=[BB[SSA:29..31]15 - org.apache.hadoop.hbase.ipc.BlockingRpcConnection.writeRequest(Lorg/apache/hadoop/hbase/ipc/Call;)V, BB[SSA:26..28]14 - org.apache.hadoop.hbase.ipc.BlockingRpcConnection.writeRequest(Lorg/apache/hadoop/hbase/ipc/Call;)V, BB[SSA:32..32]16 - org.apache.hadoop.hbase.ipc.BlockingRpcConnection.writeRequest(Lorg/apache/hadoop/hbase/ipc/Call;)V], numberOfBasicBlocks=3, firstLineNumber=614, lastLineNumber=621, firstMethodNumber=603, lastMethodNumber=644, isFirstLineValid=true, methodSrcCode=
  private void writeRequest(Call call) throws IOException {
    ByteBuf cellBlock = null;
    try {
      cellBlock = this.rpcClient.cellBlockBuilder.buildCellBlock(this.codec, this.compressor,
        call.cells, PooledByteBufAllocator.DEFAULT);
      CellBlockMeta cellBlockMeta;
      if (cellBlock != null) {
        cellBlockMeta = CellBlockMeta.newBuilder().setLength(cellBlock.readableBytes()).build();
      } else {
        cellBlockMeta = null;
      }
      RequestHeader requestHeader = buildRequestHeader(call, cellBlockMeta);

      setupIOstreams();

      // Now we're going to write the call. We take the lock, then check that the connection
      // is still valid, and, if so we do the write to the socket. If the write fails, we don't
      // know where we stand, we have to close the connection.
      if (Thread.interrupted()) {
        throw new InterruptedIOException();
      }

      calls.put(call.id, call); // We put first as we don't want the connection to become idle.
      // from here, we do not throw any exception to upper layer as the call has been tracked in
      // the pending calls map.
      try {
        call.callStats.setRequestSizeBytes(write(this.out, requestHeader, call.param, cellBlock));
      } catch (Throwable t) {
        if (LOG.isTraceEnabled()) {
          LOG.trace("Error while writing {}", call.toShortString());
        }
        IOException e = IPCUtil.toIOE(t);
        closeConn(e);
        return;
      }
    } finally {
      if (cellBlock != null) {
        cellBlock.release();
      }
    }
    notifyAll();
  }

}
