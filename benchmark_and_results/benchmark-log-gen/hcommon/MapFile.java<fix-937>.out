====================TaintedSinkInfo:=======================
-------------TaintedSinkInfo----------
fileName:	MapFile.java	methodSinagture:	org.apache.hadoop.io.MapFile.fix(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Ljava/lang/Class;Ljava/lang/Class;ZLorg/apache/hadoop/conf/Configuration;)J	methodLines:	937:1013
blockLines:	995:-1
paras:	io.map.index.interval
TaintedStat:	NORMAL fix:conditional branch(lt, to iindex=227) 77,8 Node: < Application, Lorg/apache/hadoop/io/MapFile, fix(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Ljava/lang/Class;Ljava/lang/Class;ZLorg/apache/hadoop/conf/Configuration;)J > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/io/MapFile, fix(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Ljava/lang/Class;Ljava/lang/Class;ZLorg/apache/hadoop/conf/Configuration;)J > Context: Everywhere[22]21 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getInt(Ljava/lang/String;I)I > 6,18,19 @45 exception:20
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/io/MapFile, fix(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Ljava/lang/Class;Ljava/lang/Class;ZLorg/apache/hadoop/conf/Configuration;)J > Context: Everywhere[22]21 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getInt(Ljava/lang/String;I)I > 6,18,19 @45 exception:20
NORMAL fix:75 = conversion(J) 21 Node: < Application, Lorg/apache/hadoop/io/MapFile, fix(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Ljava/lang/Class;Ljava/lang/Class;ZLorg/apache/hadoop/conf/Configuration;)J > Context: Everywhere
NORMAL fix:76 = binaryop(add) 90 , 75 Node: < Application, Lorg/apache/hadoop/io/MapFile, fix(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Ljava/lang/Class;Ljava/lang/Class;ZLorg/apache/hadoop/conf/Configuration;)J > Context: Everywhere
NORMAL fix:77 = compare 88,76 opcode=cmp Node: < Application, Lorg/apache/hadoop/io/MapFile, fix(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Ljava/lang/Class;Ljava/lang/Class;ZLorg/apache/hadoop/conf/Configuration;)J > Context: Everywhere
NORMAL fix:conditional branch(lt, to iindex=227) 77,8 Node: < Application, Lorg/apache/hadoop/io/MapFile, fix(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Ljava/lang/Class;Ljava/lang/Class;ZLorg/apache/hadoop/conf/Configuration;)J > Context: Everywhere



====================ExtendedBlocks:=======================


====================MethodSrc:=======================
                         Configuration conf) throws Exception {
    String dr = (dryrun ? "[DRY RUN ] " : "");
    Path data = new Path(dir, DATA_FILE_NAME);
    Path index = new Path(dir, INDEX_FILE_NAME);
    int indexInterval = conf.getInt(Writer.INDEX_INTERVAL, 128);
    if (!fs.exists(data)) {
      // there's nothing we can do to fix this!
      throw new Exception(dr + "Missing data file in " + dir + ", impossible to fix this.");
    }
    if (fs.exists(index)) {
      // no fixing needed
      return -1;
    }
    SequenceFile.Reader dataReader = 
      new SequenceFile.Reader(conf, SequenceFile.Reader.file(data));
    if (!dataReader.getKeyClass().equals(keyClass)) {
      throw new Exception(dr + "Wrong key class in " + dir + ", expected" + keyClass.getName() +
                          ", got " + dataReader.getKeyClass().getName());
    }
    if (!dataReader.getValueClass().equals(valueClass)) {
      throw new Exception(dr + "Wrong value class in " + dir + ", expected" + valueClass.getName() +
                          ", got " + dataReader.getValueClass().getName());
    }
    long cnt = 0L;
    Writable key = ReflectionUtils.newInstance(keyClass, conf);
    Writable value = ReflectionUtils.newInstance(valueClass, conf);
    SequenceFile.Writer indexWriter = null;
    if (!dryrun) {
      indexWriter = 
        SequenceFile.createWriter(conf, 
                                  SequenceFile.Writer.file(index), 
                                  SequenceFile.Writer.keyClass(keyClass), 
                                  SequenceFile.Writer.valueClass
                                    (LongWritable.class));
    }
    try {
      /** What's the position (in bytes) we wrote when we got the last index */
      long lastIndexPos = -1;
      /**
       * What was size when we last wrote an index. Set to MIN_VALUE to ensure
       * that we have an index at position zero - midKey will throw an exception
       * if this is not the case
       */
      long lastIndexKeyCount = Long.MIN_VALUE;
      long pos = dataReader.getPosition();
      LongWritable position = new LongWritable();
      long nextBlock = pos;
      boolean blockCompressed = dataReader.isBlockCompressed();
      while(dataReader.next(key, value)) {
        if (blockCompressed) {
          long curPos = dataReader.getPosition();
          if (curPos > nextBlock) {
            pos = nextBlock;                       // current block position
            nextBlock = curPos;
          }
        }
        // Follow the same logic as in
        // {@link MapFile.Writer#append(WritableComparable, Writable)}
        if (cnt >= lastIndexKeyCount + indexInterval && pos > lastIndexPos) {
          position.set(pos);
          if (!dryrun) {
            indexWriter.append(key, position);
          }
          lastIndexPos = pos;
          lastIndexKeyCount = cnt;
        }
        if (!blockCompressed) {
          pos = dataReader.getPosition();         // next record position
        }
        cnt++;
      }
    } catch(Throwable t) {
      // truncated data file. swallow it.
    }
    dataReader.close();
    if (!dryrun) indexWriter.close();
    return cnt;
  }


====================ctx:=======================
