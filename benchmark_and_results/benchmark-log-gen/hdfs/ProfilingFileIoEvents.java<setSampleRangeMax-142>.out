====================TaintedSinkInfo:=======================
-------------TaintedSinkInfo----------
fileName:	ProfilingFileIoEvents.java	methodSinagture:	org.apache.hadoop.hdfs.server.datanode.ProfilingFileIoEvents.setSampleRangeMax(I)V	methodLines:	142:152
blockLines:	144:-1
paras:	dfs.namenode.checkpoint.txns
TaintedStat:	NORMAL setSampleRangeMax:conditional branch(le, to iindex=12) 2,6 Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/ProfilingFileIoEvents, setSampleRangeMax(I)V > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere[130]62 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getLong(Ljava/lang/String;J)J > 58,59,60 @303 exception:61
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere[130]62 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getLong(Ljava/lang/String;J)J > 58,59,60 @303 exception:61
NORMAL run:76 = compare 75,62 opcode=cmp Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere
NORMAL run:conditional branch(ge, to iindex=196) 76,28 Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere
NORMAL run:conditional branch(eq, to iindex=231) 81,82 Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere
NORMAL run:87 = invokestatic < Application, Lorg/apache/hadoop/util/Time, monotonicNow()J > @532 exception:86 Node: < Application, Lorg/apache/hadoop/hdfs/server/namenode/ImageServlet$2, run()Ljava/lang/Void; > Context: Everywhere
METHOD_ENTRY:Node: < Extension, Lorg/apache/hadoop/util/Time, monotonicNow()J > Context: Everywhere
NORMAL monotonicNow:return 5 Node: < Extension, Lorg/apache/hadoop/util/Time, monotonicNow()J > Context: Everywhere
NORMAL_RET_CALLEE:Node: < Extension, Lorg/apache/hadoop/util/Time, monotonicNow()J > Context: Everywhere
NORMAL_RET_CALLER:Node: < Extension, Lorg/apache/hadoop/util/Shell, run()V > Context: Everywhere[5]7 = invokestatic < Extension, Lorg/apache/hadoop/util/Time, monotonicNow()J > @9 exception:6
NORMAL run:8 = compare 5,7 opcode=cmp Node: < Extension, Lorg/apache/hadoop/util/Shell, run()V > Context: Everywhere
NORMAL run:conditional branch(le, to iindex=10) 8,9 Node: < Extension, Lorg/apache/hadoop/util/Shell, run()V > Context: Everywhere
NORMAL run:invokespecial < Extension, Lorg/apache/hadoop/util/Shell, runCommand()V > 1 @37 exception:15 Node: < Extension, Lorg/apache/hadoop/util/Shell, run()V > Context: Everywhere
METHOD_ENTRY:Node: < Extension, Lorg/apache/hadoop/util/Shell, runCommand()V > Context: Everywhere
NORMAL runCommand:invokevirtual < Extension, Ljava/lang/Thread, start()V > 71 @271 exception:73 Node: < Extension, Lorg/apache/hadoop/util/Shell, runCommand()V > Context: Everywhere
METHOD_ENTRY:Node: synthetic < Primordial, Ljava/lang/Thread, start()V > Context: Everywhere
NORMAL start:invokeinterface < Primordial, Ljava/lang/Runnable, run()V > 4 @5 exception:5 Node: synthetic < Primordial, Ljava/lang/Thread, start()V > Context: Everywhere
METHOD_ENTRY:Node: < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase$ReconfigurationThread, run()V > Context: Everywhere
NORMAL run:conditional branch(eq, to iindex=159) 25,26 Node: < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase$ReconfigurationThread, run()V > Context: Everywhere
NORMAL run:conditional branch(ne, to iindex=83) 42,26 Node: < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase$ReconfigurationThread, run()V > Context: Everywhere
NORMAL run:87 = getfield < Extension, Lorg/apache/hadoop/conf/ReconfigurationUtil$PropertyChange, newVal, <Extension,Ljava/lang/String> > 29 Node: < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase$ReconfigurationThread, run()V > Context: Everywhere
PARAM_CALLER:Node: < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase$ReconfigurationThread, run()V > Context: Everywhere[122]89 = invokevirtual < Extension, Lorg/apache/hadoop/conf/ReconfigurableBase, reconfigurePropertyImpl(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > 85,86,87 @277 exception:88 v87
PARAM_CALLEE:Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, reconfigurePropertyImpl(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere v3
PARAM_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, reconfigurePropertyImpl(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere[564]84 = invokespecial < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, reconfSlowDiskParameters(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > 1,2,3 @1277 exception:83 v3
PARAM_CALLEE:Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, reconfSlowDiskParameters(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere v3
NORMAL reconfSlowDiskParameters:conditional branch(ne, to iindex=82) 3,5 Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, reconfSlowDiskParameters(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere
PHI Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, reconfSlowDiskParameters(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere:51 = phi  12,50
PARAM_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, reconfSlowDiskParameters(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere[100]invokevirtual < Application, Lorg/apache/hadoop/hdfs/server/datanode/ProfilingFileIoEvents, setSampleRangeMax(I)V > 59,51 @220 exception:60 v51
PARAM_CALLEE:Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/ProfilingFileIoEvents, setSampleRangeMax(I)V > Context: Everywhere v2
NORMAL setSampleRangeMax:conditional branch(le, to iindex=12) 2,6 Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/ProfilingFileIoEvents, setSampleRangeMax(I)V > Context: Everywhere



====================ExtendedBlocks:=======================


====================MethodSrc:=======================
  public void setSampleRangeMax(int fileIOSamplingPercentage) {
    isEnabled = Util.isDiskStatsEnabled(fileIOSamplingPercentage);
    if (fileIOSamplingPercentage > 100) {
      LOG.warn(DFSConfigKeys
          .DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_KEY +
          " value cannot be more than 100. Setting value to 100");
      fileIOSamplingPercentage = 100;
    }
    sampleRangeMax = (int) ((double) fileIOSamplingPercentage / 100 *
        Integer.MAX_VALUE);
  }



====================ctx:=======================
CtxCodeBlock{node=Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/ProfilingFileIoEvents, <init>(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere, blocks=[BB[SSA:9..12]4 - org.apache.hadoop.hdfs.server.datanode.ProfilingFileIoEvents.<init>(Lorg/apache/hadoop/conf/Configuration;)V, BB[SSA:5..8]3 - org.apache.hadoop.hdfs.server.datanode.ProfilingFileIoEvents.<init>(Lorg/apache/hadoop/conf/Configuration;)V, BB[SSA:13..13]5 - org.apache.hadoop.hdfs.server.datanode.ProfilingFileIoEvents.<init>(Lorg/apache/hadoop/conf/Configuration;)V, BB[SSA:-1..-2]9 - org.apache.hadoop.hdfs.server.datanode.ProfilingFileIoEvents.<init>(Lorg/apache/hadoop/conf/Configuration;)V], numberOfBasicBlocks=4, firstLineNumber=49, lastLineNumber=54, firstMethodNumber=46, lastMethodNumber=58, isFirstLineValid=true, methodSrcCode=

  public ProfilingFileIoEvents(@Nullable Configuration conf) {
    if (conf != null) {
      int fileIOSamplingPercentage = conf.getInt(
          DFSConfigKeys.DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_KEY,
          DFSConfigKeys
              .DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_DEFAULT);
      setSampleRangeMax(fileIOSamplingPercentage);
    } else {
      isEnabled = false;
      sampleRangeMax = 0;
    }
  }

}
CtxCodeBlock{node=Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, reconfSlowDiskParameters(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; > Context: Everywhere, blocks=[BB[SSA:99..100]48 - org.apache.hadoop.hdfs.server.datanode.DataNode.reconfSlowDiskParameters(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;, BB[SSA:98..98]47 - org.apache.hadoop.hdfs.server.datanode.DataNode.reconfSlowDiskParameters(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;, BB[SSA:101..103]49 - org.apache.hadoop.hdfs.server.datanode.DataNode.reconfSlowDiskParameters(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;, BB[SSA:-1..-2]93 - org.apache.hadoop.hdfs.server.datanode.DataNode.reconfSlowDiskParameters(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;], numberOfBasicBlocks=4, firstLineNumber=855, lastLineNumber=857, firstMethodNumber=829, lastMethodNumber=879, isFirstLineValid=true, methodSrcCode=
      throws ReconfigurationException {
    String result = null;
    try {
      LOG.info("Reconfiguring {} to {}", property, newVal);
      if (property.equals(DFS_DATANODE_OUTLIERS_REPORT_INTERVAL_KEY)) {
        checkNotNull(dnConf, "DNConf has not been initialized.");
        String reportInterval = (newVal == null ? DFS_DATANODE_OUTLIERS_REPORT_INTERVAL_DEFAULT :
            newVal);
        result = reportInterval;
        dnConf.setOutliersReportIntervalMs(reportInterval);
        for (BPOfferService bpos : blockPoolManager.getAllNamenodeThreads()) {
          if (bpos != null) {
            for (BPServiceActor actor : bpos.getBPServiceActors()) {
              actor.getScheduler().setOutliersReportIntervalMs(
                  dnConf.outliersReportIntervalMs);
            }
          }
        }
      } else if (property.equals(DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_KEY)) {
        checkNotNull(dnConf, "DNConf has not been initialized.");
        int samplingPercentage = (newVal == null ?
            DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_DEFAULT :
            Integer.parseInt(newVal));
        result = Integer.toString(samplingPercentage);
        dnConf.setFileIoProfilingSamplingPercentage(samplingPercentage);
        if (fileIoProvider != null) {
          fileIoProvider.getProfilingEventHook().setSampleRangeMax(samplingPercentage);
        }
        if (samplingPercentage > 0 && diskMetrics == null) {
          diskMetrics = new DataNodeDiskMetrics(this,
              dnConf.outliersReportIntervalMs, getConf());
        } else if (samplingPercentage <= 0 && diskMetrics != null) {
          diskMetrics.shutdownAndWait();
        }
      } else if (property.equals(DFS_DATANODE_MIN_OUTLIER_DETECTION_DISKS_KEY)) {
        checkNotNull(diskMetrics, "DataNode disk stats may be disabled.");
        long minDisks = (newVal == null ? DFS_DATANODE_MIN_OUTLIER_DETECTION_DISKS_DEFAULT :
            Long.parseLong(newVal));
        result = Long.toString(minDisks);
        diskMetrics.setMinOutlierDetectionDisks(minDisks);
      } else if (property.equals(DFS_DATANODE_SLOWDISK_LOW_THRESHOLD_MS_KEY)) {
        checkNotNull(diskMetrics, "DataNode disk stats may be disabled.");
        long threshold = (newVal == null ? DFS_DATANODE_SLOWDISK_LOW_THRESHOLD_MS_DEFAULT :
            Long.parseLong(newVal));
        result = Long.toString(threshold);
        diskMetrics.setLowThresholdMs(threshold);
      }
      LOG.info("RECONFIGURE* changed {} to {}", property, newVal);
      return result;
    } catch (IllegalArgumentException e) {
      throw new ReconfigurationException(property, newVal, getConf().get(property), e);
    }
}
