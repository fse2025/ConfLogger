====================TaintedSinkInfo:=======================
-------------TaintedSinkInfo----------
fileName:	SaslDataTransferClient.java	methodSinagture:	org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.getSaslStreams(Ljava/net/InetAddress;Ljava/io/OutputStream;Ljava/io/InputStream;Lorg/apache/hadoop/security/token/Token;Ljavax/crypto/SecretKey;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair;	methodLines:	422:446
blockLines:	434:-1
paras:	dfs.encrypt.data.overwrite.downstream.new.qop
TaintedStat:	NORMAL getSaslStreams:conditional branch(eq, to iindex=21) 15,11 Node: < Application, Lorg/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferClient, getSaslStreams(Ljava/net/InetAddress;Ljava/io/OutputStream;Ljava/io/InputStream;Lorg/apache/hadoop/security/token/Token;Ljavax/crypto/SecretKey;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair; > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferClient, getSaslStreams(Ljava/net/InetAddress;Ljava/io/OutputStream;Ljava/io/InputStream;Lorg/apache/hadoop/security/token/Token;Ljavax/crypto/SecretKey;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair; > Context: Everywhere[11]15 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, get(Ljava/lang/String;)Ljava/lang/String; > 12,13 @21 exception:14
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferClient, getSaslStreams(Ljava/net/InetAddress;Ljava/io/OutputStream;Ljava/io/InputStream;Lorg/apache/hadoop/security/token/Token;Ljavax/crypto/SecretKey;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair; > Context: Everywhere[11]15 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, get(Ljava/lang/String;)Ljava/lang/String; > 12,13 @21 exception:14
NORMAL getSaslStreams:conditional branch(eq, to iindex=21) 15,11 Node: < Application, Lorg/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferClient, getSaslStreams(Ljava/net/InetAddress;Ljava/io/OutputStream;Ljava/io/InputStream;Lorg/apache/hadoop/security/token/Token;Ljavax/crypto/SecretKey;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair; > Context: Everywhere



====================ExtendedBlocks:=======================


====================MethodSrc:=======================
      throws IOException {
    Map<String, String> saslProps = saslPropsResolver.getClientProperties(addr);

    // secretKey != null only happens when this is called by DN
    // sending to downstream DN. If called from client, this will be null,
    // as there is no key for client to generate mac instance.
    // So that, if a different QOP is desired for inter-DN communication,
    // the check below will use new QOP to create a secret, which includes
    // the new QOP.
    if (secretKey != null) {
      String newQOP = conf
          .get(DFS_ENCRYPT_DATA_OVERWRITE_DOWNSTREAM_NEW_QOP_KEY);
      if (newQOP != null) {
        saslProps.put(Sasl.QOP, newQOP);
      }
      LOG.debug("DataNode overwriting downstream QOP " +
          saslProps.get(Sasl.QOP));
      updateToken(accessToken, secretKey, saslProps);
    }
    targetQOP = saslProps.get(Sasl.QOP);
    String userName = buildUserName(accessToken);
    char[] password = buildClientPassword(accessToken);
    CallbackHandler callbackHandler = new SaslClientCallbackHandler(userName,
        password);
    return doSaslHandshake(addr, underlyingOut, underlyingIn, userName,
        saslProps, callbackHandler, accessToken);


====================ctx:=======================
CtxCodeBlock{node=Node: < Application, Lorg/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferClient, send(Ljava/net/InetAddress;Ljava/io/OutputStream;Ljava/io/InputStream;Lorg/apache/hadoop/hdfs/security/token/block/DataEncryptionKey;Lorg/apache/hadoop/security/token/Token;Lorg/apache/hadoop/hdfs/protocol/DatanodeID;Ljavax/crypto/SecretKey;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair; > Context: Everywhere, blocks=[BB[SSA:64..70]24 - org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(Ljava/net/InetAddress;Ljava/io/OutputStream;Ljava/io/InputStream;Lorg/apache/hadoop/hdfs/security/token/block/DataEncryptionKey;Lorg/apache/hadoop/security/token/Token;Lorg/apache/hadoop/hdfs/protocol/DatanodeID;Ljavax/crypto/SecretKey;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair;, BB[SSA:59..63]23 - org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(Ljava/net/InetAddress;Ljava/io/OutputStream;Ljava/io/InputStream;Lorg/apache/hadoop/hdfs/security/token/block/DataEncryptionKey;Lorg/apache/hadoop/security/token/Token;Lorg/apache/hadoop/hdfs/protocol/DatanodeID;Ljavax/crypto/SecretKey;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair;, BB[SSA:71..71]25 - org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(Ljava/net/InetAddress;Ljava/io/OutputStream;Ljava/io/InputStream;Lorg/apache/hadoop/hdfs/security/token/block/DataEncryptionKey;Lorg/apache/hadoop/security/token/Token;Lorg/apache/hadoop/hdfs/protocol/DatanodeID;Ljavax/crypto/SecretKey;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair;, BB[SSA:-1..-2]28 - org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(Ljava/net/InetAddress;Ljava/io/OutputStream;Ljava/io/InputStream;Lorg/apache/hadoop/hdfs/security/token/block/DataEncryptionKey;Lorg/apache/hadoop/security/token/Token;Lorg/apache/hadoop/hdfs/protocol/DatanodeID;Ljavax/crypto/SecretKey;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair;], numberOfBasicBlocks=4, firstLineNumber=286, lastLineNumber=289, firstMethodNumber=263, lastMethodNumber=298, isFirstLineValid=true, methodSrcCode=
      throws IOException {
    if (encryptionKey != null) {
      LOG.debug("SASL client doing encrypted handshake for addr = {}, "
          + "datanodeId = {}", addr, datanodeId);
      return getEncryptedStreams(addr, underlyingOut, underlyingIn,
          encryptionKey, accessToken, secretKey);
    } else if (!UserGroupInformation.isSecurityEnabled()) {
      LOG.debug("SASL client skipping handshake in unsecured configuration for "
          + "addr = {}, datanodeId = {}", addr, datanodeId);
      return null;
    } else if (SecurityUtil.isPrivilegedPort(datanodeId.getXferPort())) {
      LOG.debug(
          "SASL client skipping handshake in secured configuration with "
              + "privileged port for addr = {}, datanodeId = {}",
          addr, datanodeId);
      return null;
    } else if (fallbackToSimpleAuth != null && fallbackToSimpleAuth.get()) {
      LOG.debug(
          "SASL client skipping handshake in secured configuration with "
              + "unsecured cluster for addr = {}, datanodeId = {}",
          addr, datanodeId);
      return null;
    } else if (saslPropsResolver != null) {
      LOG.debug(
          "SASL client doing general handshake for addr = {}, datanodeId = {}",
          addr, datanodeId);
      return getSaslStreams(addr, underlyingOut, underlyingIn,
          accessToken, secretKey);
    } else {
      // It's a secured cluster using non-privileged ports, but no SASL.  The
      // only way this can happen is if the DataNode has
      // ignore.secure.ports.for.testing configured so this is a rare edge case.
      LOG.debug("SASL client skipping handshake in secured configuration with "
              + "no SASL protection configured for addr = {}, datanodeId = {}",
          addr, datanodeId);
      return null;
    }
}
